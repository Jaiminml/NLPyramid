{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9cf768",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b3911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "data = \"\"\"Natural language processing (NLP) is a subfield of linguistics.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57fbc77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "(  :  (\n",
      "NLP  :  nlp\n",
      ")  :  )\n",
      "is  :  is\n",
      "a  :  a\n",
      "subfield  :  subfield\n",
      "of  :  of\n",
      "linguistics  :  linguist\n",
      ".  :  .\n"
     ]
    }
   ],
   "source": [
    "# import PorterStemmer and tokenization from nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "     \n",
    "# To use Class PorterStemmer create a variable\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Apply tokenization on data\n",
    "tokens = word_tokenize(data)\n",
    "\n",
    "for word in tokens:\n",
    "    print(word,\" : \",ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9478d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  :  nat\n",
      "language  :  langu\n",
      "processing  :  process\n",
      "(  :  (\n",
      "NLP  :  nlp\n",
      ")  :  )\n",
      "is  :  is\n",
      "a  :  a\n",
      "subfield  :  subfield\n",
      "of  :  of\n",
      "linguistics  :  lingu\n",
      ".  :  .\n"
     ]
    }
   ],
   "source": [
    "# import LancasterStemmer and tokenization from nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "     \n",
    "# To use Class PorterStemmer create a variable\n",
    "ls = LancasterStemmer()\n",
    "\n",
    "# Apply tokenization on data\n",
    "tokens = word_tokenize(data)\n",
    "\n",
    "for word in tokens:\n",
    "    print(word,\" : \",ls.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d521946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "(  :  (\n",
      "NLP  :  nlp\n",
      ")  :  )\n",
      "is  :  is\n",
      "a  :  a\n",
      "subfield  :  subfield\n",
      "of  :  of\n",
      "linguistics  :  linguist\n",
      ".  :  .\n"
     ]
    }
   ],
   "source": [
    "# import LancasterStemmer and tokenization from nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "     \n",
    "# To use Class PorterStemmer create a variable\n",
    "ss = SnowballStemmer(language=\"english\")\n",
    "\n",
    "# Apply tokenization on data\n",
    "tokens = word_tokenize(data)\n",
    "\n",
    "for word in tokens:\n",
    "    print(word,\" : \",ss.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e47dfa",
   "metadata": {},
   "source": [
    "We can see that porter stemmer takes \"Natur\" as a base root of natural while other stemmer take \"nat\" as a base root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fcb1425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Porter Stemmer      lancaster Stemmer   \n",
      "friend              friend              friend              \n",
      "friendship          friendship          friend              \n",
      "friends             friend              friend              \n",
      "friendships         friendship          friend              \n",
      "stabil              stabil              stabl               \n",
      "destabilize         destabil            dest                \n",
      "misunderstanding    misunderstand       misunderstand       \n",
      "railroad            railroad            railroad            \n",
      "moonlight           moonlight           moonlight           \n",
      "football            footbal             footbal             \n",
      "singing             sing                sing                \n",
      "sang                sang                sang                \n",
      "sing                sing                sing                \n"
     ]
    }
   ],
   "source": [
    "#Let's take a set of word to check the difference between porter and lancaster stemmer.\n",
    "\n",
    "#A list of words to be stemmed\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\",\"singing\",\"sang\",\"sing\"]\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word,ps.stem(word),ls.stem(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41aa04a",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe1710b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jaiminmungalpara/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9dbadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural  :  Natural\n",
      "language  :  language\n",
      "processing  :  processing\n",
      "(  :  (\n",
      "NLP  :  NLP\n",
      ")  :  )\n",
      "is  :  is\n",
      "a  :  a\n",
      "subfield  :  subfield\n",
      "of  :  of\n",
      "linguistics  :  linguistics\n",
      ".  :  .\n"
     ]
    }
   ],
   "source": [
    "# import WordNetLemmatizer and tokenization from nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "     \n",
    "# To use Class PorterStemmer create a variable\n",
    "WL = WordNetLemmatizer()\n",
    "\n",
    "# Apply tokenization on data\n",
    "tokens = word_tokenize(data)\n",
    "\n",
    "for word in tokens:\n",
    "    print(word,\" : \",WL.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ac1bc",
   "metadata": {},
   "source": [
    "We can see that all the words are having their base root now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c427fd04",
   "metadata": {},
   "source": [
    "# StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adddcd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaiminmungalpara/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96e23225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a subfield of linguistics.\n",
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', '.']\n"
     ]
    }
   ],
   "source": [
    "# import stopwords and tokenization from nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#take a list of stop words in a variable\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "  \n",
    "tokens = word_tokenize(data)\n",
    "  \n",
    "filtered_words = []\n",
    "  \n",
    "for w in tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_words.append(w)\n",
    "print(data)\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e4d85",
   "metadata": {},
   "source": [
    "## Let's create a custom stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d3d0c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) subfield linguistics.\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS, remove_stopwords\n",
    "\n",
    "filtered_sentence = remove_stopwords(data)\n",
    "\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f24dab",
   "metadata": {},
   "source": [
    "## Now we will add \"subfield\" in stopword's list and check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3f9f34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'linguistics', '.']\n"
     ]
    }
   ],
   "source": [
    "all_stopwords_gensim = STOPWORDS.union(set(['subfield']))\n",
    "\n",
    "\n",
    "tokens = word_tokenize(data)\n",
    "clean_words = [word for word in tokens if not word in all_stopwords_gensim]\n",
    "\n",
    "print(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ff8cc",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "785e1824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Natural',)\n",
      "('language',)\n",
      "('processing',)\n",
      "('(NLP)',)\n",
      "('is',)\n",
      "('a',)\n",
      "('subfield',)\n",
      "('of',)\n",
      "('linguistics.',)\n"
     ]
    }
   ],
   "source": [
    "#import ngrams from nltk \n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "n = 1\n",
    "\n",
    "unigrams = ngrams(data.split(), n)\n",
    "\n",
    "for item in unigrams:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3846dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Natural', 'language')\n",
      "('language', 'processing')\n",
      "('processing', '(NLP)')\n",
      "('(NLP)', 'is')\n",
      "('is', 'a')\n",
      "('a', 'subfield')\n",
      "('subfield', 'of')\n",
      "('of', 'linguistics.')\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "\n",
    "unigrams = ngrams(data.split(), n)\n",
    "\n",
    "for item in unigrams:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e0aabb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Natural', 'language', 'processing')\n",
      "('language', 'processing', '(NLP)')\n",
      "('processing', '(NLP)', 'is')\n",
      "('(NLP)', 'is', 'a')\n",
      "('is', 'a', 'subfield')\n",
      "('a', 'subfield', 'of')\n",
      "('subfield', 'of', 'linguistics.')\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "unigrams = ngrams(data.split(), n)\n",
    "\n",
    "for item in unigrams:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cff3b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural',),\n",
       " ('Natural', 'language'),\n",
       " ('Natural', 'language', 'processing'),\n",
       " ('Natural', 'language', 'processing', '(NLP)'),\n",
       " ('Natural', 'language', 'processing', '(NLP)', 'is'),\n",
       " ('Natural', 'language', 'processing', '(NLP)', 'is', 'a'),\n",
       " ('Natural', 'language', 'processing', '(NLP)', 'is', 'a', 'subfield'),\n",
       " ('Natural', 'language', 'processing', '(NLP)', 'is', 'a', 'subfield', 'of'),\n",
       " ('Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  '(NLP)',\n",
       "  'is',\n",
       "  'a',\n",
       "  'subfield',\n",
       "  'of',\n",
       "  'linguistics.'),\n",
       " ('language',),\n",
       " ('language', 'processing'),\n",
       " ('language', 'processing', '(NLP)'),\n",
       " ('language', 'processing', '(NLP)', 'is'),\n",
       " ('language', 'processing', '(NLP)', 'is', 'a'),\n",
       " ('language', 'processing', '(NLP)', 'is', 'a', 'subfield'),\n",
       " ('language', 'processing', '(NLP)', 'is', 'a', 'subfield', 'of'),\n",
       " ('language',\n",
       "  'processing',\n",
       "  '(NLP)',\n",
       "  'is',\n",
       "  'a',\n",
       "  'subfield',\n",
       "  'of',\n",
       "  'linguistics.'),\n",
       " ('processing',),\n",
       " ('processing', '(NLP)'),\n",
       " ('processing', '(NLP)', 'is'),\n",
       " ('processing', '(NLP)', 'is', 'a'),\n",
       " ('processing', '(NLP)', 'is', 'a', 'subfield'),\n",
       " ('processing', '(NLP)', 'is', 'a', 'subfield', 'of'),\n",
       " ('processing', '(NLP)', 'is', 'a', 'subfield', 'of', 'linguistics.'),\n",
       " ('(NLP)',),\n",
       " ('(NLP)', 'is'),\n",
       " ('(NLP)', 'is', 'a'),\n",
       " ('(NLP)', 'is', 'a', 'subfield'),\n",
       " ('(NLP)', 'is', 'a', 'subfield', 'of'),\n",
       " ('(NLP)', 'is', 'a', 'subfield', 'of', 'linguistics.'),\n",
       " ('is',),\n",
       " ('is', 'a'),\n",
       " ('is', 'a', 'subfield'),\n",
       " ('is', 'a', 'subfield', 'of'),\n",
       " ('is', 'a', 'subfield', 'of', 'linguistics.'),\n",
       " ('a',),\n",
       " ('a', 'subfield'),\n",
       " ('a', 'subfield', 'of'),\n",
       " ('a', 'subfield', 'of', 'linguistics.'),\n",
       " ('subfield',),\n",
       " ('subfield', 'of'),\n",
       " ('subfield', 'of', 'linguistics.'),\n",
       " ('of',),\n",
       " ('of', 'linguistics.'),\n",
       " ('linguistics.',)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import ngrams from nltk \n",
    "\n",
    "from nltk.util import everygrams\n",
    "\n",
    "tokens = data.split()\n",
    "\n",
    "list(everygrams(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83930e9",
   "metadata": {},
   "source": [
    "## We can use Textblob library also for N-gram implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8e194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
